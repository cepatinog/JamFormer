{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìí Add paths and import required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root and utils to sys.path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))           # for model.py\n",
    "sys.path.append(os.path.abspath(\"../utils\"))     # for utils.py, logger.py\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from model import ChordConditionedMelodyTransformer\n",
    "from utils import pitch_to_midi\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìí Define the model configuration\n",
    "Make sure this matches your hparams.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration (should match training)\n",
    "model_config = {\n",
    "    \"num_pitch\": 50,\n",
    "    \"frame_per_bar\": 16,\n",
    "    \"num_bars\": 8,\n",
    "    \"chord_emb_size\": 128,\n",
    "    \"pitch_emb_size\": 256,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"key_dim\": 512,\n",
    "    \"value_dim\": 512,\n",
    "    \"num_layers\": 8,\n",
    "    \"num_heads\": 16,\n",
    "    \"input_dropout\": 0.2,\n",
    "    \"layer_dropout\": 0.2,\n",
    "    \"attention_dropout\": 0.2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìí Load the trained model from checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model checkpoint\n",
    "checkpoint_path = \"/home/cepatinog/smc-assignments/final_project/my_jazz_project/results/idx002/model/checkpoint_70.pth.tar\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "model = ChordConditionedMelodyTransformer(**model_config)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded and ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìí Chord helper function\n",
    "\n",
    "Convert chord names to 12-dimensional binary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chord dictionary (expand as needed)\n",
    "def roman_to_chord_vector(roman):\n",
    "    chord_templates = {\n",
    "        'C': [0, 4, 7],\n",
    "        'F': [5, 9, 0],\n",
    "        'G': [7, 11, 2],\n",
    "        'Am': [9, 0, 4],\n",
    "        'Dm': [2, 5, 9],\n",
    "        'Em': [4, 7, 11]\n",
    "    }\n",
    "    vec = np.zeros(12)\n",
    "    for p in chord_templates.get(roman, []):\n",
    "        vec[p % 12] = 1\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìí Create a custom chord progression and convert to tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 bars √ó 16 frames per bar = 128 time steps\n",
    "progression = ['C', 'Am', 'F', 'G', 'C', 'Am', 'F', 'G']\n",
    "frames_per_bar = model_config[\"frame_per_bar\"]\n",
    "max_len = model_config[\"num_bars\"] * frames_per_bar\n",
    "\n",
    "chord_matrix = np.zeros((max_len, 12))\n",
    "for i, chord in enumerate(progression):\n",
    "    vec = roman_to_chord_vector(chord)\n",
    "    chord_matrix[i * frames_per_bar:(i + 1) * frames_per_bar] = vec\n",
    "\n",
    "chord_tensor = torch.tensor(chord_matrix).unsqueeze(0).float()  # shape: [1, 128, 12]\n",
    "print(f\"‚úÖ chord_tensor shape: {chord_tensor.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìí Generate melody from scratch (no prime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty prime (start from scratch)\n",
    "prime_rhythm = torch.zeros((1, 0), dtype=torch.long)\n",
    "prime_pitch = torch.zeros((1, 0), dtype=torch.long)\n",
    "\n",
    "# Sampling\n",
    "with torch.no_grad():\n",
    "    result = model.sampling(prime_rhythm, prime_pitch, chord_tensor, topk=3)\n",
    "\n",
    "pitch = result[\"pitch\"][0].numpy()\n",
    "rhythm = result[\"rhythm\"][0].numpy()\n",
    "print(\"‚úÖ Melody generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"generated_custom.mid\"\n",
    "pitch_to_midi(pitch, chord_matrix, frame_per_bar=frames_per_bar, save_path=output_path)\n",
    "print(f\"‚úÖ MIDI saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "midi_data = pretty_midi.PrettyMIDI(output_path)\n",
    "melody_roll = midi_data.instruments[0].get_piano_roll(fs=16)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(melody_roll, origin='lower', aspect='auto', cmap='gray_r')\n",
    "plt.title(\"Generated Melody - Piano Roll\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"MIDI Pitch\")\n",
    "plt.savefig(\"generated_custom_pianoroll.png\")\n",
    "print(\"‚úÖ Piano roll saved as generated_custom_pianoroll.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Lista de acordes disponibles\n",
    "available_chords = ['C', 'F', 'G', 'Am', 'Dm', 'Em']\n",
    "\n",
    "# Crear 8 men√∫s desplegables (uno por comp√°s)\n",
    "chord_selectors = [widgets.Dropdown(options=available_chords, description=f'Bar {i+1}:') for i in range(8)]\n",
    "generate_button = widgets.Button(description=\"Generate Chord Tensor\", button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_generate_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        # Leer progresi√≥n seleccionada\n",
    "        progression = [dropdown.value for dropdown in chord_selectors]\n",
    "        print(\"üéº Selected progression:\", progression)\n",
    "        \n",
    "        # Generar matriz de acordes\n",
    "        frames_per_bar = model_config[\"frame_per_bar\"]\n",
    "        total_frames = frames_per_bar * len(progression)\n",
    "        chord_matrix = np.zeros((total_frames, 12))\n",
    "        for i, chord in enumerate(progression):\n",
    "            vec = roman_to_chord_vector(chord)\n",
    "            chord_matrix[i * frames_per_bar:(i + 1) * frames_per_bar] = vec\n",
    "\n",
    "        # Convertir a tensor y asignar globalmente\n",
    "        global chord_tensor\n",
    "        chord_tensor = torch.tensor(chord_matrix).unsqueeze(0).float()\n",
    "        print(f\"‚úÖ chord_tensor shape: {chord_tensor.shape} (ready to sample)\")\n",
    "\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "# Mostrar UI\n",
    "display(widgets.VBox(chord_selectors + [generate_button, output_area]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.sampling(prime_rhythm, prime_pitch, chord_tensor, topk=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")  # where chord_library.py was saved\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import chord_library as chords\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# All available Roman numeral chords from the module\n",
    "available_chords = list(chords.ROMAN_TO_DEGREES.keys())\n",
    "\n",
    "# Create 8 dropdowns\n",
    "chord_selectors = [widgets.Dropdown(options=available_chords, value='I', description=f'Bar {i+1}') for i in range(8)]\n",
    "generate_button = widgets.Button(description=\"Generate Chord Tensor\", button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_generate_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        selected_progression = [selector.value for selector in chord_selectors]\n",
    "        print(\"üéº Selected progression:\", selected_progression)\n",
    "\n",
    "        try:\n",
    "            matrix = chords.chord_progression_to_matrix(selected_progression, frames_per_chord=16)\n",
    "            global chord_tensor\n",
    "            chord_tensor = torch.tensor(matrix).unsqueeze(0).float()\n",
    "            print(f\"‚úÖ chord_tensor ready with shape: {chord_tensor.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "# Display UI\n",
    "display(widgets.VBox(chord_selectors + [generate_button, output_area]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result = model.sampling(prime_rhythm, prime_pitch, chord_tensor, topk=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = result[\"pitch\"][0].numpy()\n",
    "rhythm = result[\"rhythm\"][0].numpy()\n",
    "print(\"‚úÖ Melody generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"generated_custom2.mid\"\n",
    "pitch_to_midi(pitch, chord_matrix, frame_per_bar=frames_per_bar, save_path=output_path)\n",
    "print(f\"‚úÖ MIDI saved as {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
